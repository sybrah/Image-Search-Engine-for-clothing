{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f2f98d-e46f-4604-81fd-7cbc80ef7703",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Optional\n",
    "from dotenv import load_dotenv\n",
    "from io import BytesIO\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.docstore.document import Document\n",
    "import chromadb\n",
    "\n",
    "\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Define environment variables\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_KEY\")\n",
    "CHAINLIT_API_KEY = os.getenv(\"CHAINLIT_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Define paths and collection name\n",
    "CHROMA_DATA_PATH = r\"./embeddings_database\" \n",
    "COLLECTION_NAME = \"SearchEngine\"\n",
    "\n",
    "# Initialize the language model\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo-16k\")\n",
    "\n",
    "def get_bert_embedding(text):\n",
    "    \"\"\"Generates an embedding for the given text using BERT.\"\"\"\n",
    "    # Tokenize and encode the text\n",
    "    encoded_text = bert_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    \n",
    "    # Get the model output\n",
    "    with torch.no_grad():  # Disable gradient calculation for efficiency\n",
    "        outputs = bert_model(**encoded_text)\n",
    "    \n",
    "    # Get the last hidden state (typically used for embeddings)\n",
    "    embeddings = outputs.last_hidden_state[:, 0, :]  # Take the first token's embedding (CLS token)\n",
    "    \n",
    "    # Convert the tensor to a list\n",
    "    embeddings_list = embeddings.squeeze(0).tolist()  # Remove batch dimension and convert to list\n",
    "    \n",
    "    return embeddings_list\n",
    "\n",
    "\n",
    "def retrieve_and_display_images(query, collection, top_k=):\n",
    "    \"\"\"Retrieves and displays images corresponding to the top matching captions. \"\"\"\n",
    "\n",
    "    if results is None:\n",
    "        query_embedding = get_bert_embedding(query)\n",
    "        results = collection.query(query_embeddings=[query_embedding], n_results=top_k, include=[\"documents\"])\n",
    "\n",
    "    image_urls = []\n",
    "    for result in results:\n",
    "        doc_id = result['id']\n",
    "        if df is not None and 'image' in df.columns:\n",
    "            # Assuming 'image' is a column in df containing image URLs or file paths\n",
    "            image_url = df.loc[doc_id, 'image']\n",
    "            image_urls.append(image_url)\n",
    "\n",
    "    return image_urls\n",
    "\n",
    "\n",
    "@cl.password_auth_callback\n",
    "def auth_callback(username: str, password: str) -> Optional[cl.AppUser]:\n",
    "    \"\"\"Authenticates users based on credentials.\"\"\"\n",
    "\n",
    "    if (username, password) == (\"admin\", \"admin\"):\n",
    "        return cl.AppUser(username=\"admin\", role=\"ADMIN\", provider=\"credentials\")\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "@cl.on_chat_start\n",
    "async def main():\n",
    "    \"\"\"Handles initial chat setup and retrieves relevant documents based on user input.\"\"\"\n",
    "\n",
    "    # Call the vectorDB and the embeddings function\n",
    "    client = chromadb.PersistentClient(CHROMA_DATA_PATH)\n",
    "    huggingface_embeddings = HuggingFaceEmbeddings(\n",
    "        \n",
    "\n",
    "\n",
    "@cl.on_chat_start\n",
    "async def main():\n",
    "    \"\"\"Handles initial chat setup and retrieves relevant documents based on user input.\"\"\"\n",
    "\n",
    "    # Call the vectorDB and the embeddings function\n",
    "    client = chromadb.PersistentClient(CHROMA_DATA_PATH)\n",
    "    huggingface_embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"google-bert/bert-base-uncased\",\n",
    "        model_kwargs={\"device\": \"cpu\"},\n",
    "    )\n",
    "    text_splitter = SentenceSplitter()  # Add text splitter for sentence-level embeddings\n",
    "\n",
    "    # Use the ChromaDB langchain wrapper (consider caching the Chroma instance)\n",
    "    langchain_chroma = Chroma(\n",
    "        client=client,\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        embedding_function=huggingface_embeddings,\n",
    "        text_splitter=text_splitter,  # Pass the text splitter to Chroma\n",
    "    )\n",
    "    retriever = langchain_chroma.as_retriever(search_kwargs={\"k\": 3}, search_type=\"similarity\")\n",
    "    cl.user_session.set(\"retriever\", retriever)  # Store retriever for later use\n",
    "\n",
    "    query = None\n",
    "    while query is None:\n",
    "        query = await cl.AskUserMessage(\n",
    "            content=\"Please give a discription of the image \",\n",
    "            author=\"Search Engine\",\n",
    "            max_size_mb=10,\n",
    "        ).send()\n",
    "    if query:\n",
    "        # Process and display\n",
    "        await cl.Message(content=f\"Looking for an image of {query['content']}..\",\n",
    "                        author=\"Search Engine\").send()\n",
    "        image_urls = await cl.make_async(retrieve_and_display_images)(df)  # Assuming you have a DataFrame `your_dataframe` containing image data\n",
    "        await cl.message(content=\"Here are images similar to your description:\").send()\n",
    "        for image_url in image_urls:\n",
    "            await cl.image(image_url=image_url).send()  # Display retrieved images\n",
    "\n",
    "    #=============================== Ask for an action =====================================================\n",
    "    res=await cl.AskActionMessage(content=\"Are you satisfied with this answer ?\",\n",
    "                                    actions=[\n",
    "                                        cl.Action(name=\"YES\" , value=\"YES\", label=\"YES\"),\n",
    "                                        cl.Action(name=\"NO\" , value=\"NO\", label=\"NO\")\n",
    "                                    ]).send()\n",
    "    if res and res.get('value')==\"YES\":\n",
    "                                    await cl.Message(content=\"YES!\").send()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
